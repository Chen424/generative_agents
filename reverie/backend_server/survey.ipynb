{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single survey POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from reverie import ReverieServer\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def suppress_output():\n",
    "    # Save the current stdout\n",
    "    original_stdout = sys.stdout\n",
    "    # Redirect stdout to the null device\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        # Restore the original stdout\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove temp folder if it exists\n",
    "if os.path.exists(\"../../environment/frontend_server/storage/_temp\"):\n",
    "    os.system(\"rm -rf ../../environment/frontend_server/storage/_temp\")\n",
    "\n",
    "PATH = \"base_the_ville_smol_elections_5_voters_2days/base_the_ville_smol_elections_5_voters_2days-s-142-15463-15594\"\n",
    "\n",
    "rs = ReverieServer(PATH, \"_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with suppress_output():\n",
    "#     o = rs.personas[\"Maria Lopez\"].open_convo_session(\"analysis\", direct=True, question=\"Who are you planning to vote in the coming elections?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:24<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "source": [
    "survey_question = \"Who are you planning to vote in the coming elections?\"\n",
    "\n",
    "convos = []\n",
    "for persona in tqdm(rs.personas.values()):\n",
    "    with suppress_output():\n",
    "        convos.append(persona.open_convo_session(\"analysis\", direct=True, question=survey_question)[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Isabella Rodriguez',\n",
       "  'I am still in the process of evaluating the candidates Klaus Mauller and Maria Lopez for the upcoming town elections. I am planning to discuss my thoughts on this matter with Adam Smith over coffee at Hobbs Cafe tomorrow. I want to make an informed decision and consider the best candidate for our community.'],\n",
       " ['Maria Lopez',\n",
       "  \"I'm still undecided at the moment. I'm researching and learning more about the candidates and their policies before making my decision. It's important to me to make an informed choice based on the issues that matter most to me and my community.\"],\n",
       " ['Klaus Mueller',\n",
       "  \"I haven't decided yet. I'm still gathering information on the candidates and their platforms. I think it's important to make an informed decision based on their stance on issues that matter to me, like social justice and community development.\"],\n",
       " ['Abigail Chen',\n",
       "  \"I'm still exploring all the candidates' proposals and attending events to understand their platforms better. I am planning to meet with Maria Lopez to discuss her proposals, and I have also been following Klaus Mauller's campaign. I want to make an informed decision based on their ideas and plans for our town.\"],\n",
       " ['Adam Smith',\n",
       "  'I am planning to vote for Maria Lopez in the upcoming elections. I have had the opportunity to discuss policies and backgrounds with her, and I believe she is the best candidate for affordable housing and urban development in our town.'],\n",
       " ['Arthur Burton',\n",
       "  \"I am planning to attend Maria Lopez's event to learn more about her community engagement platform and ways to support the candidates moving forward. I am also discussing research findings on Maria Lopez and Klaus Mauller's backgrounds with Adam Smith and planning to compare policies and proposals to make informed decisions to support both candidates' campaigns.\"],\n",
       " ['Ayesha Khan',\n",
       "  \"I haven't decided yet. I am still researching and analyzing the candidates and their platforms to make an informed decision. It's important to me to vote for someone who aligns with my values and priorities.\"]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import persona.prompt_template.gpt_structure as gpt_structure\n",
    "\n",
    "gpt_param = {\"engine\": \"gpt-35-turbo-0125\", \"max_tokens\": 250, \n",
    "            \"temperature\": 0, \"top_p\": 1, \"stream\": False,\n",
    "            \"frequency_penalty\": 0, \"presence_penalty\": 0, \"stop\": None}\n",
    "\n",
    "extract_prompt = \"You are given a response to a survey question \\\"Who are you planning to vote in the coming elections?\\\". Extract and write the name of the candidate mentioned in the response or write None if the responder have not decided yet. Respond with the name of the candidate or None. Response: {response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person: Isabella Rodriguez\n",
      "Response: I am still in the process of evaluating the candidates Klaus Mauller and Maria Lopez for the upcoming town elections. I am planning to discuss my thoughts on this matter with Adam Smith over coffee at Hobbs Cafe tomorrow. I want to make an informed decision and consider the best candidate for our community.\n",
      "Predicted: None\n",
      "\n",
      "\n",
      "\n",
      "Person: Maria Lopez\n",
      "Response: I'm still undecided at the moment. I'm researching and learning more about the candidates and their policies before making my decision. It's important to me to make an informed choice based on the issues that matter most to me and my community.\n",
      "Predicted: None\n",
      "\n",
      "\n",
      "\n",
      "Person: Klaus Mueller\n",
      "Response: I haven't decided yet. I'm still gathering information on the candidates and their platforms. I think it's important to make an informed decision based on their stance on issues that matter to me, like social justice and community development.\n",
      "Predicted: None\n",
      "\n",
      "\n",
      "\n",
      "Person: Abigail Chen\n",
      "Response: I'm still exploring all the candidates' proposals and attending events to understand their platforms better. I am planning to meet with Maria Lopez to discuss her proposals, and I have also been following Klaus Mauller's campaign. I want to make an informed decision based on their ideas and plans for our town.\n",
      "Predicted: None\n",
      "\n",
      "\n",
      "\n",
      "Person: Adam Smith\n",
      "Response: I am planning to vote for Maria Lopez in the upcoming elections. I have had the opportunity to discuss policies and backgrounds with her, and I believe she is the best candidate for affordable housing and urban development in our town.\n",
      "Predicted: Maria Lopez\n",
      "\n",
      "\n",
      "\n",
      "Person: Arthur Burton\n",
      "Response: I am planning to attend Maria Lopez's event to learn more about her community engagement platform and ways to support the candidates moving forward. I am also discussing research findings on Maria Lopez and Klaus Mauller's backgrounds with Adam Smith and planning to compare policies and proposals to make informed decisions to support both candidates' campaigns.\n",
      "Predicted: Maria Lopez\n",
      "\n",
      "\n",
      "\n",
      "Person: Ayesha Khan\n",
      "Response: I haven't decided yet. I am still researching and analyzing the candidates and their platforms to make an informed decision. It's important to me to vote for someone who aligns with my values and priorities.\n",
      "Predicted: None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for convo in convos:\n",
    "    print(f\"Person: {convo[0]}\")\n",
    "    print(f\"Response: {convo[-1]}\")\n",
    "    print(f\"Predicted: {gpt_structure.GPT_request(extract_prompt.format(response=convo[-1]), gpt_param)}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multisurvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import persona.prompt_template.gpt_structure as gpt_structure\n",
    "from reverie import ReverieServer\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def suppress_output():\n",
    "    # Save the current stdout\n",
    "    original_stdout = sys.stdout\n",
    "    # Redirect stdout to the null device\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        # Restore the original stdout\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "def get_folders(path):\n",
    "    return [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "\n",
    "def clean_start_server(path):\n",
    "    if os.path.exists(\"../../environment/frontend_server/storage/_temp\"):\n",
    "        os.system(\"rm -rf ../../environment/frontend_server/storage/_temp\")\n",
    "\n",
    "    rs = ReverieServer(path, \"_temp\")\n",
    "    return rs\n",
    "\n",
    "def get_survey_responses(rs, survey_question):\n",
    "    convos = []\n",
    "    for persona in tqdm(rs.personas.values()):\n",
    "        with suppress_output():\n",
    "            convos.append(persona.open_convo_session(\"analysis\", direct=True, question=survey_question)[-1])\n",
    "    return convos\n",
    "\n",
    "def extract_survey_responses(convos, extract_prompt, gpt_param):\n",
    "    predictions = []\n",
    "    for convo in convos:\n",
    "        predictions.append((convo[-1], gpt_structure.GPT_request(extract_prompt.format(response=convo[-1]), gpt_param)))\n",
    "    return predictions\n",
    "\n",
    "def update_results(results, predictions):\n",
    "    for i, (response, prediction) in enumerate(predictions):\n",
    "        if prediction in results:\n",
    "            results[prediction] += 1\n",
    "        else:\n",
    "            results[prediction] = 1\n",
    "    return results\n",
    "\n",
    "def save_file(results, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "def load_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "gpt_param = {\"engine\": \"gpt-35-turbo-0125\", \"max_tokens\": 250, \n",
    "            \"temperature\": 0, \"top_p\": 1, \"stream\": False,\n",
    "            \"frequency_penalty\": 0, \"presence_penalty\": 0, \"stop\": None}\n",
    "\n",
    "extract_survey_prompt = \"You are given a response to a survey question \\\"Who are you planning to vote in the coming elections?\\\". Extract and write the name of the candidate mentioned in the response or write None if the responder have not decided yet. Respond with the name of the candidate or None. Response: {response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:16<00:00,  2.39s/it]\n",
      "  1%|          | 1/151 [00:19<49:11, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.57s/it]\n",
      "  1%|▏         | 2/151 [00:40<50:49, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.58s/it]\n",
      "  2%|▏         | 3/151 [01:01<51:14, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.74s/it]\n",
      "  3%|▎         | 4/151 [01:24<52:33, 21.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.62s/it]\n",
      "  3%|▎         | 5/151 [01:46<52:28, 21.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.69s/it]\n",
      "  4%|▍         | 6/151 [02:08<53:08, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 6, 'Klaus Mauller': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.89s/it]\n",
      "  5%|▍         | 7/151 [02:32<54:22, 22.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:17<00:00,  2.51s/it]\n",
      "  5%|▌         | 8/151 [02:56<54:25, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.66s/it]\n",
      "  6%|▌         | 9/151 [03:18<53:52, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Klaus Mauller': 1, 'None': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:16<00:00,  2.35s/it]\n",
      "  7%|▋         | 10/151 [03:41<53:15, 22.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.91s/it]\n",
      "  7%|▋         | 11/151 [04:06<54:25, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:21<00:00,  3.02s/it]\n",
      "  8%|▊         | 12/151 [04:31<55:47, 24.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.91s/it]\n",
      "  9%|▊         | 13/151 [04:56<56:04, 24.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  2.96s/it]\n",
      "  9%|▉         | 14/151 [05:23<57:05, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.73s/it]\n",
      " 10%|▉         | 15/151 [05:47<55:54, 24.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:20<00:00,  3.00s/it]\n",
      " 11%|█         | 16/151 [06:12<56:14, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.80s/it]\n",
      " 11%|█▏        | 17/151 [06:37<55:19, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.67s/it]\n",
      " 12%|█▏        | 18/151 [07:00<54:08, 24.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.59s/it]\n",
      " 13%|█▎        | 19/151 [07:23<52:44, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.70s/it]\n",
      " 13%|█▎        | 20/151 [07:47<52:02, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.63s/it]\n",
      " 14%|█▍        | 21/151 [08:10<51:16, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.71s/it]\n",
      " 15%|█▍        | 22/151 [08:34<50:49, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.65s/it]\n",
      " 15%|█▌        | 23/151 [08:57<50:33, 23.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.74s/it]\n",
      " 16%|█▌        | 24/151 [09:21<50:09, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "PATH_SIM = \"base_the_ville_smol_elections_5_voters_2days\"\n",
    "\n",
    "folders = get_folders(f\"../../environment/frontend_server/storage/{PATH_SIM}\")\n",
    "folders_sorted = sorted(folders, key=lambda x: int(x.split(\"-\")[-3]))\n",
    "\n",
    "results = []\n",
    "all_convos = []\n",
    "all_predictions = []\n",
    "df_survey = pd.DataFrame(columns=list(map(lambda x: x.split(\"-\")[-3], folders_sorted)))\n",
    "for PATH_STAGE in tqdm(folders_sorted):\n",
    "    rs = clean_start_server(f\"{PATH_SIM}/{PATH_STAGE}\")\n",
    "    convos = get_survey_responses(rs, \"Who are you planning to vote in the coming elections?\")\n",
    "    predictions = extract_survey_responses(convos, extract_survey_prompt, gpt_param)\n",
    "    \n",
    "    results.append(update_results({}, predictions))\n",
    "    all_convos.append(convos)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "    save_file(results[-1], f\"results.pkl\")\n",
    "    save_file(all_convos[-1], f\"convos.pkl\")\n",
    "    save_file(all_predictions[-1], f\"predictions.pkl\")\n",
    "    print(results[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulacra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
